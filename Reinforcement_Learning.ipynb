{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOK75oPZfRigqnpkyiPNYRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnupriya-ms/My-Projects/blob/main/Reinforcement_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8M3WSbJCERQl"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "\n",
        "class SampleEnvironment: # Defined a simple sample class here\n",
        "  def __init__(self):\n",
        "    self.steps_left=20   #maximum number of steps agent can take inoreder to get maximum reward\n",
        "\n",
        "  def get_observation(self)->List[int]:\n",
        "      return[0.0,0.0,0.0]  # any kind of coordinates ====> Information regarding the environment\n",
        "\n",
        "  def get_actions(self)->List[int]: #When the agent gets some specific actions the agent gets 1 for positive reward and 0 for negative reward\n",
        "      return[0,1]\n",
        "\n",
        "  def is_done(self)->bool: #When the step is completed we send some boolean value\n",
        "      return self.steps_left==0\n",
        "\n",
        "  def action(self,action:int)->float: #Whether the agent take an action  or not\n",
        "    if self.is_done():\n",
        "       raise Exception(\"Game is over\")\n",
        "    self.steps_left -=1\n",
        "    return random.random()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "  def __init__(self):\n",
        "    self.total_reward=0.0\n",
        "\n",
        "  def step(self,env:SampleEnvironment):\n",
        "      current_obs=env.get_observation()\n",
        "      print(\"Observation{}\".format(current_obs))\n",
        "      actions=env.get_actions()\n",
        "      print(actions)\n",
        "      reward=env.action(random.choice(actions))\n",
        "      self.total_reward+=reward\n",
        "      print(\"Total Reward{}\".format(self.total_reward))"
      ],
      "metadata": {
        "id": "KQdll35LHeUe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    env = SampleEnvironment()\n",
        "    agent = Agent()\n",
        "    i=0\n",
        "    while not env.is_done():\n",
        "        i=i+1\n",
        "        print(\"Steps{}\".format(i))\n",
        "        agent.step(env)\n",
        "\n",
        "    print(\"Total reward obtained: %.4f\" % agent.total_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlkMfQl8JPBZ",
        "outputId": "e6cda1d5-7af3-490a-9852-3dc1c92d7e61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps1\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward0.12591871742027227\n",
            "Steps2\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward1.088936733054846\n",
            "Steps3\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward1.4307777716756869\n",
            "Steps4\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward2.3769289985901643\n",
            "Steps5\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward3.3098626054560745\n",
            "Steps6\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward3.631556773490232\n",
            "Steps7\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward3.790502015226483\n",
            "Steps8\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward4.218320392678593\n",
            "Steps9\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward4.40719262565164\n",
            "Steps10\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward4.538938668979736\n",
            "Steps11\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward4.688705534042793\n",
            "Steps12\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward4.988284835373902\n",
            "Steps13\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward5.561455181058004\n",
            "Steps14\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward5.906353466546384\n",
            "Steps15\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward6.9048426092168125\n",
            "Steps16\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward7.074223731346114\n",
            "Steps17\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward7.541392831006315\n",
            "Steps18\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward8.43036697022885\n",
            "Steps19\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward9.03498272369069\n",
            "Steps20\n",
            "Observation[0.0, 0.0, 0.0]\n",
            "[0, 1]\n",
            "Total Reward9.491192142065401\n",
            "Total reward obtained: 9.4912\n"
          ]
        }
      ]
    }
  ]
}